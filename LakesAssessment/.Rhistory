MaxDailyTemp$TempCatM <- as.character(MaxDailyTemp$MaxD)
MaxDailyTemp$TempCatM [MaxDailyTemp$MaxD<22.4]<- "Cold"
MaxDailyTemp$TempCatM [MaxDailyTemp$MaxD>26.3]<- "Warm"
MaxDailyTemp$TempCatM [MaxDailyTemp$MaxD>=22.4&MaxDailyTemp$MaxD<=26.3]<- "Cool"
##N Days >= 24.9 degree C and N Days >= 27 May 1 - Sept 15##
MaxDates<- MaxDay[MaxDay$month=='05'|MaxDay$month=='06'|MaxDay$month=='07'|MaxDay$month=='08'|
(MaxDay$month=='09' & MaxDay$d<=15),]
MaxDates$MaxTemp24.9<- ifelse(MaxDates$max>=24.9,1,0)
MaxDates$MaxTemp27<- ifelse(MaxDates$max>=27,1,0)
MaxGreaterThanTemp<-ddply(MaxDates,"SID",summarize,Max24.9=sum(MaxTemp24.9),Max27=sum(MaxTemp27))
##Combine and Export Metrics By Year
TempMetrics <- merge(AvgSummerTemp,AvgJulyTemp,by="SID")
TempMetrics <-merge(TempMetrics,MaxDailyTemp,by="SID")
TempMetrics <-merge(TempMetrics,MaxGreaterThanTemp,by="SID")
TempMetrics$Flag [TempMetrics$SN<92|TempMetrics$JN <31] <- 1
TempMetrics$Year<-yrCol[n,1]
TempMetrics$Collector<-yrCol[n,2]
TempMetricsAll<-rbind(TempMetricsAll,TempMetrics)
#write.csv(TempMetrics,"S:/M_Kozlak/Temperature/TemperatureDB/MetricCalcs/TempMetrics.csv",append=TRUE,row.names=FALSE)
#write.csv(TempMetrics,paste0("S:/M_Kozlak/Temperature/TemperatureDB/MetricCalcs/TempMetrics",yrCol[n,2],yrCol[n,1],".csv"),row.names=FALSE)
}
dim(TempMetricsAll)
TempMetricsAll[500:550,]
TempMetricsAll[1000:1050,]
TempMetricsAll[900:950,]
library(RSQLite)
library(plyr)
library(ggplot2)
library(lubridate)
#open ODBC
db_path <- 'S:/M_Kozlak/Temperature/TemperatureDB/' #on windows like this
db <- dbConnect(SQLite(), dbname=paste(db_path,"stream.temperature.sqlite",sep=''));
##Query with Field Flags and put into R data.fram and native R types
SELECTflag<- "SELECT probe_temps.ProbeID, probe_temps.SID, probe_temps.Date_Time, probe_temps.Temp, probe_temps.UOM, probe_temps.Collector, probe_temps.ProbeType, fieldflag.DateStart, fieldflag.DateEnd, fieldflag.COMMENT
FROM probe_temps
LEFT JOIN fieldflag ON probe_temps.ProbeID = fieldflag.ProbeID AND probe_temps.SID = fieldflag.SID AND probe_temps.Date_Time >= fieldflag.DateStart AND probe_temps.Date_Time <= fieldflag.DateEnd"
table<- dbGetQuery(db,SELECTflag)
#query/look at data as an R data.frame and native R types<<<<<<<<<<<<<<<<
#look at some data
#names  <- dbListTables(db);                        # The tables in the database
#fields <- dbListFields(db, "probe_temps");    # The columns in a table
#table  <- dbReadTable(db, "probe_temps");  # get the whole table as a data.frame
#Summarize data by day
table$day <- substr(table$Date_Time,6,10)##Add column of data that includes month_day
table$month<- substr(table$Date_Time,6,7)##Add column of data that includes month
table$year<- substr(table$Date_Time,1,4)##Add column of data that includes year
table$date<-ymd_hms(table$Date_Time)
TempMetricsAll<-data.frame(SID=character(),SummerTemp=numeric(),SN=numeric(),TempCatS=character(),JulyTemp=numeric(),JN=numeric(),
TempCatJ=character(),MaxD=numeric(),MN=numeric(),TempCatM=character(),
Max24.9=numeric(),Max27=numeric(),Flag=numeric(),Year=character(),Collector=character())
SummerMonthCnt<-table[table$month=='06'|table$month=='07'|table$month=='08',]
yrCol<- unique(SummerMonthCnt[,c('year','Collector')])
for (n in 1:dim(yrCol)[1]){
temp <- table[which(table$Collector==yrCol[n,2] & table$year==yrCol[n,1]),]##Subset by Year and Collector
AvgDay <- ddply(temp,c("SID","day","month","year"),summarize,mean=mean(Temp),N=length(Temp))#AvgByDay
AvgDay$day<-as.numeric(substr(AvgDay$day,4,5))
MaxDay<- ddply(temp,c("SID","day","month","year"),summarize,max=max(Temp),N=length(Temp))#MaxOnAGivenDay
MaxDay$d<-as.numeric(substr(MaxDay$day,4,5))
##Avg Summer Temp##
SummerMonths <- AvgDay[AvgDay$month=='06'|AvgDay$month=='07'|AvgDay$month=='08'&AvgDay$N>=24,]
AvgSummerTemp <- ddply(SummerMonths,"SID",summarize,SummerTemp=mean(mean),SN=length(mean))#Summer Temp Month
AvgSummerTemp$TempCatS <- AvgSummerTemp$SummerTemp
AvgSummerTemp$TempCatS<- as.character(AvgSummerTemp$TempCat)
AvgSummerTemp$TempCatS[AvgSummerTemp$SummerTemp<18.29]<-"Cold"
AvgSummerTemp$TempCatS[AvgSummerTemp$SummerTemp>21.7]<-"Warm"
AvgSummerTemp$TempCatS[AvgSummerTemp$SummerTemp>=18.29&AvgSummerTemp$SummerTemp<=21.7]<-"Cool"
##Avg July Temp##
July<- AvgDay[AvgDay$month=='07'& AvgDay$N>=24,]
AvgJulyTemp <- ddply(July,"SID",summarize,JulyTemp=mean(mean),JN=length(mean))#Summer Temp Month
AvgJulyTemp$TempCatJ <- AvgJulyTemp$JulyTemp
AvgJulyTemp$TempCatJ<- as.character(AvgJulyTemp$TempCat)
AvgJulyTemp$TempCatJ[AvgJulyTemp$JulyTemp<18.45]<-"Cold"
AvgJulyTemp$TempCatJ[AvgJulyTemp$JulyTemp>22.30]<-"Warm"
AvgJulyTemp$TempCatJ[AvgJulyTemp$JulyTemp>=18.45&AvgJulyTemp$JulyTemp<=22.30]<-"Cool"
##Max Daily Mean##
MaxDailyTemp <- ddply(AvgDay,"SID",summarize,MaxD = max(mean),MN=length(mean))
MaxDailyTemp$TempCatM <- MaxDailyTemp$MaxD
MaxDailyTemp$TempCatM <- as.character(MaxDailyTemp$MaxD)
MaxDailyTemp$TempCatM [MaxDailyTemp$MaxD<22.4]<- "Cold"
MaxDailyTemp$TempCatM [MaxDailyTemp$MaxD>26.3]<- "Warm"
MaxDailyTemp$TempCatM [MaxDailyTemp$MaxD>=22.4&MaxDailyTemp$MaxD<=26.3]<- "Cool"
##N Days >= 24.9 degree C and N Days >= 27 May 1 - Sept 15##
MaxDates<- MaxDay[MaxDay$month=='05'|MaxDay$month=='06'|MaxDay$month=='07'|MaxDay$month=='08'|
(MaxDay$month=='09' & MaxDay$d<=15),]
MaxDates$MaxTemp24.9<- ifelse(MaxDates$max>=24.9,1,0)
MaxDates$MaxTemp27<- ifelse(MaxDates$max>=27,1,0)
MaxGreaterThanTemp<-ddply(MaxDates,"SID",summarize,Max24.9=sum(MaxTemp24.9),Max27=sum(MaxTemp27))
##Combine and Export Metrics By Year
TempMetrics <- merge(AvgSummerTemp,AvgJulyTemp,by="SID")
TempMetrics <-merge(TempMetrics,MaxDailyTemp,by="SID")
TempMetrics <-merge(TempMetrics,MaxGreaterThanTemp,by="SID")
TempMetrics$Flag [TempMetrics$SN<92|TempMetrics$JN <31] <- 1
TempMetrics$Year<-yrCol[n,1]
TempMetrics$Collector<-yrCol[n,2]
TempMetricsAll<-rbind(TempMetricsAll,TempMetrics)
#write.csv(TempMetrics,"S:/M_Kozlak/Temperature/TemperatureDB/MetricCalcs/TempMetrics.csv",append=TRUE,row.names=FALSE)
#write.csv(TempMetrics,paste0("S:/M_Kozlak/Temperature/TemperatureDB/MetricCalcs/TempMetrics",yrCol[n,2],yrCol[n,1],".csv"),row.names=FALSE)
}
write.csv(TempMetricsAll,"TempMetricsAllSamples.csv",row.names=FALSE)
write.csv(TempMetricsAll,"S:/M_Kozlak/Temperature/TemperatureDB/MetricCalcs/TempMetricsAllSamples.csv",row.names=FALSE)
library('RSQLite')
db_path <- 'P:/Projects/2019/LakeSedimentDiatoms/LakeDiatomDB'
db <- dbConnect(SQLite(), dbname=paste(db_path,"lake_diatom.sqlite",sep=''));
SQL <- "CREATE TABLE diatom_cnts
(
SITE_ID text not null,
BENCH_NAME text not null,
BiodataTaxonName text not null,
COUNT integer not null
);"
dbSendQuery(conn=db,SQL);
dbDisconnect(db);
db_path <- 'P:/Projects/2019/LakeSedimentDiatoms/LakeDiatomDB/'
db <- dbConnect(SQLite(), dbname=paste(db_path,"lake_diatom.sqlite",sep=''));
SQL <- "CREATE TABLE diatom_cnts
(
SITE_ID text not null,
BENCH_NAME text not null,
BiodataTaxonName text not null,
COUNT integer not null
);"
dbSendQuery(conn=db,SQL);
dbGetQuery(db,'SELECT * FROM diatom_cnts')
SQL <- "CREATE TABLE diatom_taxa
(
BenchTaxonName text,
TaxonConceptState	text,
BiologicalCommunity text,
AlgalGroup text,
BenchTaxonProvisional text,
BenchTaxonHybrid text,
BiodataTaxonName text,
BiodataCommonName text,
BiodataShortName text,
BiodataTaxonProvisional text,
BiodataTaxonHybrid text,
PublishedTaxonLevel text,
ScientificName text,
Phylum text,
Class	Order_ text,
Family text,
Genus	text,
Species	text,
Subspecies text,
Variety text,
Form text
);"
dbSendQuery(conn=db,SQL);
library('RSQLite')
library('lubridate')
db_path <- 'S:/J_Tonfa/5YrMonitoringRpt'
db <- dbConnect(SQLite(), dbname=paste(db_path,"monrpt.sqlite",sep=''));
SQL<- " SELECT *
FROM chemdata;"
sQL
SQL
dbGetQuery(conn=db,SQL)
db
dbDisconnect(db);
dbDisconnect(db);
db_path <- 'S:/J_Tonfa/5YrMonitoringRpt'
db <- dbConnect(SQLite(), dbname=paste(db_path,"monrpt.db",sep=''));
SQL<- " SELECT *
FROM chemdata;"
dbGetQuery(conn=db,SQL)
dbDisconnect(db);
paste(db_path,"monrpt.db",sep='')
db_path <- 'S:/J_Tonfa/5YrMonitoringRpt/'
db <- dbConnect(SQLite(), dbname=paste(db_path,"monrpt.db",sep=''));
SQL<- " SELECT *
FROM chemdata;"
dbGetQuery(conn=db,SQL)
SQL<- "SELECT sta_seq
FROM chemdata
GROUP BY sta_seq;"
table<-dbGetQuery(conn=db,SQL)
table
SQL<- "SELECT *
FROM chemdata;"
table<-dbGetQuery(conn=db,SQL); #Executes the query above and puts data into a dataframe (R data structure)
class(table)
class(table$value)
table[table$value==NA,]
table[where(table$value==NA),]
table[which(table$value==NA),]
table[1:10,]
unique(table$chemparameter)
names(table)
Chloride<-table[chemparameter=="Chloride"&duplicate==0,]
Chloride<-table[table$chemparameter=="Chloride"&table$duplicate==0,]
unique(Chloride$uom)
summary(chloride$value)
chloride<-table[table$chemparameter=="Chloride"&table$duplicate==0,]
#Make sure all chem values have the same UOM
unique(Chloride$uom)
summary(chloride$value)
summary(chloride$value)[1]
SQL<-"SELECT *
FROM basins;"
basins<-dbGetQuery(conn=db,SQL)
SQL<-"SELECT *
FROM basin;"
basin<-dbGetQuery(conn=db,SQL)
names(basin)
majbasin<-basin[,c("mbasn","major")]
SQL<-"SELECT
major,
mbasn
FROM basin
GROUP BY
mbasn;"
majbasin<-dbGetQuery(conn=db,SQL)
majbasin
table
names(table)
SQL<- "SELECT *
FROM chemdata
WHERE
station_type="River/Stream";"
table<-dbGetQuery(conn=db,SQL); #Executes the query above and puts data into a dataframe (R data structure)
SQL<- "SELECT *
FROM chemdata
WHERE
station_type='River/Stream';"
table<-dbGetQuery(conn=db,SQL); #Executes the query above and puts data into a dataframe (R data structure)
table[1:10,]
##Get all unique chemistry parameters
unique(table$chemparameter)
##Get the column names of the dataframe
names(table)
##Subset a table by columns
table[,c("sta_seq","chemparameter","value","uom","duplicate")]
names(table)
table[,c("sta_seq","collect_date","chemparameter","value","uom","duplicate")]
table[,c(1,3:6,12)]
table<-table[,c(1,3:6,12)]
SQL<-"SELECT
sites.sta_seq,
sites.name,
sites.ylat,
site.xlong,
sites.sbasn
basin.major,
basin.mbasn
FROM sites
JOIN basin
ON
sites.sbasn = basin.sbasn;"
sitesbasin<-dbGetQuery(conn=db,SQL)
SQL<-"SELECT
sites.sta_seq,
sites.name,
sites.ylat,
site.xlong,
sites.sbasn
basin.major,
basin.mbasn
FROM
sites
JOIN
basin
ON
sites.sbasn = basin.sbasn;"
sitesbasin<-dbGetQuery(conn=db,SQL)
SQL<-"SELECT
sites.sta_seq,
sites.name,
sites.ylat,
site.xlong,
sites.sbasn,
basin.major,
basin.mbasn
FROM
sites
JOIN
basin
ON
sites.sbasn = basin.sbasn;"
sitesbasin<-dbGetQuery(conn=db,SQL)
SQL<-"SELECT
sites.sta_seq,
sites.name,
sites.ylat,
sites.xlong,
sites.sbasn,
basin.major,
basin.mbasn
FROM
sites
JOIN
basin
ON
sites.sbasn = basin.sbasn;"
sitesbasin<-dbGetQuery(conn=db,SQL)
sitesbasin
table_basin<-merge(table,sitesbasin,by="sta_seq")
table_basin[1:10,]
chloride<-table_basin[table_basin$chemparameter=="Chloride"&table_basin$duplicate==0,]
table<-table[,c(1,3:6,11:12)]
table<-table[,c(1,3:6,11,12)]
SQL<- "SELECT *
FROM
chemdata
WHERE
station_type='River/Stream';"
table<-dbGetQuery(conn=db,SQL); #Executes the query above and puts data into a dataframe (R data structure)
table<-table[,c(1,3:6,11:12)]
table_basin<-merge(table,sitesbasin,by="sta_seq")
chloride<-table_basin[table_basin$chemparameter=="Chloride"&table_basin$duplicate==0,]
unique(Chloride$uom)
unique(table$station_type)
summary(chloride$value)
by(chloride["value"]),INDICES=list(MajorBasin=unique(table_basin$major)),FUN=summary)
by(chloride["value"],INDICES=list(MajorBasin=unique(table_basin$major)),FUN=summary)
by(chloride["value"],INDICES=list(MajorBasin=unique(table_basin$major)),FUN=range)
chloride["value"]
INDICES=list(MajorBasin=unique(table_basin$major))
INDICES
aggregate(chloride["value"],INDICES=list(MajorBasin=unique(table_basin$major)),FUN=mean)
aggregate(chloride["value"],by=list(MajorBasin=unique(table_basin$major)),FUN=mean)
aggregate(chloride["value"],by=list(MajorBasin=unique(chloride$major)),FUN=mean)
aggregate(chloride["value"],by=list(MajorBasin=chloride$major),FUN=mean)
aggregate(chloride["value"],by=list(MajorBasin=chloride$major),FUN=summary)
aggregate(chloride["value"],by=list(MajorBasin=chloride$major),FUN=n)
aggregate(chloride["value"],by=list(MajorBasin=chloride$major),FUN=length)
length(chloride$value)
class(table_basin)
class(table_basin$value)
library('RSQLite')
#The purpose of this script is to flag duplicate pairs that fall outside
#of a predefined acceptable range in terms of difference
#Uses field replicate percentage
#open ODBC
db_path <- 'S:/J_Tonfa/5YrMonitoringRpt/'
db <- dbConnect(SQLite(), dbname=paste(db_path,"monrpt.db",sep=''));
#SQL query for duplicates using following criteria
#same: chemparameter, sta_seq, collection date, duplicate (0 to 1)
#Create dataframe of duplicates
#note: assume chem dataframe already has desired chemparameter
SQL <- "select
c.sta_seq,
c.chemparameter,
c.collect_date,
c.value as 'value1',
c2.value as 'value2',
c.uom
from chemdata c, chemdata c2
where
c.sta_seq = c2.sta_seq
and c.collect_date = c2.collect_date
and c.chemparameter = c2.chemparameter
and (c.duplicate + c2.duplicate) = 1 --check that there is only one duplicate
and c.station_type='River/Stream'
and c2.station_type='River/Stream'
;"
table <- dbGetQuery(conn=db, SQL)
SQL <- "select *
from chemQA"
table_QA <- dbGetQuery(conn=db, SQL)
SQL <- "SELECT *
FROM mdl;"
table_mdl <- dbGetQuery(conn=db, SQL)
dbDisconnect(db);
library(RSQLite)
library(plyr)
library(ggplot2)
library(lubridate)
#open ODBC
db_path <- 'S:/M_Kozlak/Temperature/TemperatureDB/' #on windows like this
db <- dbConnect(SQLite(), dbname=paste(db_path,"stream.temperature.sqlite",sep=''));
##Query with Field Flags and put into R data.fram and native R types
SELECTflag<- "SELECT probe_temps.ProbeID, probe_temps.SID, probe_temps.Date_Time, probe_temps.Temp, probe_temps.UOM, probe_temps.Collector, probe_temps.ProbeType, fieldflag.DateStart, fieldflag.DateEnd, fieldflag.COMMENT
FROM probe_temps
LEFT JOIN fieldflag ON probe_temps.ProbeID = fieldflag.ProbeID AND probe_temps.SID = fieldflag.SID AND probe_temps.Date_Time >= fieldflag.DateStart AND probe_temps.Date_Time <= fieldflag.DateEnd"
table<- dbGetQuery(db,SELECTflag)
#query/look at data as an R data.frame and native R types<<<<<<<<<<<<<<<<
#look at some data
#names  <- dbListTables(db);                        # The tables in the database
#fields <- dbListFields(db, "probe_temps");    # The columns in a table
#table  <- dbReadTable(db, "probe_temps");  # get the whole table as a data.frame
#Summarize data by day
table$day <- substr(table$Date_Time,6,10)##Add column of data that includes month_day
table$month<- substr(table$Date_Time,6,7)##Add column of data that includes month
table$year<- substr(table$Date_Time,1,4)##Add column of data that includes year
table$date<-ymd_hms(table$Date_Time)
##Write CSV of Avg Day with Flag for all records##
AvgDay <- ddply(table,c("ProbeID","SID","day","month","year","Collector","UOM","COMMENT"),summarize,mean=mean(Temp),min=min(Temp),
max=max(Temp),maxmin= (max(Temp)-min(Temp)),N=length(Temp))#AvgByDay
AvgDay$Flag [AvgDay$N<24|AvgDay$min<0|AvgDay$maxmin>5|AvgDay$mean>=30]<-1
AvgDay$Flag [!is.na(AvgDay$COMMENT)]<-1
Flag<- AvgDay[,c(1:5,13)]
SHEDS<- merge(x=table,y=Flag,by=c("ProbeID","SID","day","month","year"),all.x=TRUE)
SHEDS<- SHEDS[is.na(SHEDS[,'Flag']),]
SHEDS<- SHEDS[which(SHEDS$year==2017& SHEDS$Collector=='ABM'),]
SHEDS<- SHEDS[,c(2,6,7)]
SHEDS<-SHEDS[order(SHEDS$SID,SHEDS$Date_Time),]
dbDisconnect(db);
setwd("P:/Projects/GitHub_Prj/Lakes/LakesAssessment")
library(ggplot2)
library(grid)
library(gridExtra)
library(rgdal)
library(sp)
library(sf)
library(png)
library(tmap)
library(dplyr)
ysi<-read.csv("data/YSILakes2019.csv",header=TRUE,stringsAsFactors = FALSE)
samples<-read.csv("data/samples_2019.csv",header=TRUE,stringsAsFactors = FALSE)
ysisampleck<-unique(ysi[c("awq","date")])
samples<-merge(ysisampleck,samples,by=c("awq","date"))
lakespoly<-read_sf("data/lakes_poly.geojson")
lakespts<-read_sf("data/lakes_pt.geojson")
cttownspoly<-read_sf("data/CTTowns.geojson")
samples
ysi
maxtemp<- max(ysi$temp)
maxdo<-max(ysi$do_mgl)
maxchlor<-max(ysi$chlor_rfu)
maxbga<-max(ysi$bga_rfu)
maxtemp
maxdo
maxchlor
maxbga
for (i in 1:dim(samples)[1]){
st<-samples$awq[i]
dt<-samples$date[i]
s<-ysi[which(ysi$awq==st&ysi$date==dt),]
s<-s[order(s$depth),]
p1<-  ggplot(s,aes(temp,depth))+
geom_path(size=1.5)+
scale_y_reverse(limits=c(max(s$depth),0))+
xlim(0,maxtemp)+
labs(y="Depth (m)",x=expression(paste("Temperature (",degree,"C)")),
title=expression(paste("Temperature (",degree,"C)")))+
theme_classic()+
theme(text=element_text(size=14))+
theme(plot.margin=unit(c(1,1,1.5,1.5),"cm"))
p2<-  ggplot(s,aes(do_mgl,depth))+
geom_path(size=1.5)+
scale_y_reverse(limits=c(max(s$depth),0))+
xlim(0,maxdo)+
labs(y="Depth (m)",x="Dissolved Oxygen (mg/L)",title="Dissolved Oxygen (mg/L)")+
theme_classic()+
theme(text=element_text(size=14))+
theme(plot.margin=unit(c(1,1,1.5,1.5),"cm"))
p3<-  ggplot(s,aes(chlor_rfu,depth))+
geom_path(size=1.5)+
scale_y_reverse(limits=c(max(s$depth),0))+
xlim(0,maxchlor)+
labs(y="Depth (m)",x="Chlorophyll (rfu)",
title="Chlorophyll (rfu)")+
theme_classic()+
theme(text=element_text(size=14))+
theme(plot.margin=unit(c(1,1,1.5,1.5),"cm"))
p4<-  ggplot(s,aes(bga_rfu,depth))+
geom_path(size=1.5)+
scale_y_reverse(limits=c(max(s$depth),0))+
xlim(0,maxbga)+
labs(y="Depth (m)",x="Phycocyanin Blue-Green Algae (rfu)",
title="Phycocyanin (rfu)")+
theme_classic()+
theme(text=element_text(size=14))+
theme(plot.margin=unit(c(1,1,1.5,1.5),"cm"))
##Parse out the lake data that you are interested in
lakemappt<-lakespts[which(lakespts$STA_SEQ==st),]
lakemappoly<-lakespoly[which(lakespoly$GNIS_ID==lakemappt$GNIS_ID),]
##Make a map of the parsed lake data
smap<-  tm_shape(cttownspoly)+
tm_polygons(col="gray",border.col="white",lwd=2)+
tm_shape(lakemappt)+
tm_symbols(col="black")+
tm_layout(bg.color="midnightblue")
lmap<-  tm_shape(lakemappoly)+
tm_polygons(col="deepskyblue1",border.col="white",lwd=3,border.alpha=0.7)+
tm_shape(lakemappt)+
tm_symbols(col="black")+
tm_layout(bg.color="midnightblue")
wmap<-tmap_arrange(smap,lmap)
tmap_save(wmap,paste0("maps/",st,"map.png"),width=600,height=400,dpi=72)
map<-readPNG(paste0("maps/",st,"map.png"))
lay<-rbind(c(1,2),
c(3,2),
c(4,2),
c(5,2),
c(NA,2),
c(6,NA),
c(7,NA),
c(8,NA),
c(9,10),
c(11,12))
infojust<-0
posx<-0.2
posy<-1
title<-textGrob(lakemappt$name,
gp=gpar(fontsize=25,fontface="bold", col="black"),posx,posy,just=infojust)
sdate<-textGrob(paste("Sample Date:",dt),
gp=gpar(fontsize=15,fontface="bold", col="black"),posx,posy,just=infojust)
secchi<-textGrob(paste("Secchi Depth (m):",samples$secchi_m[i]),
gp=gpar(fontsize=15,fontface="bold", col="black"),posx,posy,just=infojust)
depth<-textGrob(paste("Total Depth (m):",samples$tdepth_m[i]),
gp=gpar(fontsize=15,fontface="bold", col="black"),posx,posy,just=infojust)
acre<-textGrob(paste("Acres:",round(lakemappoly$area_acre,2)),posx,posy,just=infojust)
town<-textGrob(paste("Town:",lakemappt$town),posx,posy,just=infojust)
basin<-textGrob(paste("Drainage Basin:",lakemappt$sbas_nm),posx,posy,just=infojust)
map<-rasterGrob(map)
laketest<-grid.arrange(title,map,sdate,secchi,depth,acre,town,basin,p1,p2,p3,p4,
ncol=2,layout_matrix=lay,
heights=unit(c(0.5,0.5,0.5,0.5,1,0.25,0.25,0.25,3,3),
c("in","in","in","in","in","in","in","in","in")))
ggsave(paste("ysipdf/",st,lakemappt$name,gsub('/','-',dt),"ysi.pdf"),laketest,width=8,height=11,units="in",dpi=72)
}
